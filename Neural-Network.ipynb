{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "# Keras: Machine Learning Library (Includes MNIST Dataset)\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Matplotlib: Data Visualization Library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training inputs shape is (60000, 28, 28)\n",
      "Training labels:\n",
      "[5 0 4 ... 5 6 8]\n",
      "Training labels shape is (60000,)\n",
      "\n",
      "Test inputs shape is (10000, 28, 28)\n",
      "Test labels:\n",
      "[7 2 1 ... 4 5 6]\n",
      "Test labels shape is (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Data Exploration\n",
    "\n",
    "print(\"Training inputs shape is \" + str(x_train.shape)) # 60,000 samples, each image: 28 x 28 pixels\n",
    "print(\"Training labels:\")\n",
    "print(y_train)\n",
    "print(\"Training labels shape is \" + str(y_train.shape))\n",
    "print()\n",
    "print(\"Test inputs shape is \" + str(x_test.shape)) # 10,000 samples, each image: 28 x 28 pixels\n",
    "print(\"Test labels:\")\n",
    "print(y_test)\n",
    "print(\"Test labels shape is \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128b5b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the input samples\n",
    "\n",
    "sample_num = 0 # change this number and re-run the cell to see different image samples!\n",
    "\n",
    "# Use the matplotlib library to display the imported images\n",
    "plt.imshow(x_train[sample_num], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing the Data\n",
    "- **Flatten** the 28 x 28 2D images into 784-dimensional column vectors. Each pixel will then correspond to one neuron in the 784-dimensional input layer of our neural network.\n",
    "- **Normalize** the pixel values from 0-255 to 0-1. We can do this by simply dividing each of the 0-255 greyscale values by 255. Neural networks typically like to work with smaller values, so this normalization is a pretty common first step in most deep learning tasks.\n",
    "- **Categorize** the outputs into 10-dimensional \"one-hot\" vectors. The MNIST dataset originally contains actual numerical labels for each image (e.g. 1, 2, ...), but remember that our neural network outputs 10 distinct values (one for each digit) -- not just the digit number itself. We want our training labels to match up with our neural network output. These categorized vectors contain all 0's, except a 1 in the location indicating which digit the image corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten 28*28 images to a 784 vector for each image\n",
    "\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2] # 28 * 28 = 784\n",
    "x_train_flattened = x_train.reshape(x_train.shape[0], num_pixels).astype('float32') # new shape: 60,000 x 784\n",
    "x_test_flattened = x_test.reshape(x_test.shape[0], num_pixels).astype('float32') # new shape: 10,000 x 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to between 0-1\n",
    "\n",
    "x_train_flattened = x_train_flattened / 255.\n",
    "x_test_flattened = x_test_flattened / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Categorize the outputs with Keras (\"one-hot\" vectors)\n",
    "\n",
    "y_train_categorical = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Let's see result of categorizing the outputs\n",
    "print(y_train_categorical[:5]) # Print out first 5 training label vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Neural Network Model\n",
    "1. **Initialize** the network, add desired layers. The settings we decide to use, e.g. number of layers, number of neurons per layer, are called hyperparameters, and have to be tuned by hand, rather than learned via gradient descent.\n",
    "2. **Compile** the network to get ready for training. This tells the network what cost/loss function to use (\"cost\" and \"loss\" are used interchangeably), and what type of gradient descent to use.\n",
    "3. **Fit** the network to the training images. This actually feeds the training data into the network, and uses gradient descent and backpropagation to adjust the network's weights in order to minimize the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize simple neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Hidden layer 1: 64 neurons, 'relu' activation \n",
    "    # (see: https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
    "    # http://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\n",
    "model.add(Dense(units=64, input_dim=784, activation='relu'))\n",
    "\n",
    "# Hidden layer 2: 32 neurons, 'relu' activation\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Output layer: 10 neurons (one for each class), 'softmax' activation\n",
    "    # This layer represents the scores that the network assigns to each possible digit, 1-10\n",
    "    # See: http://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model, get ready to train\n",
    "\n",
    "    # Loss: Categorical Crossentropy\n",
    "        # See: http://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html\n",
    "    # Optimizer: stochastic gradient descent (SGD)\n",
    "    # Additional metrics: Accuracy\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 52,650\n",
      "Trainable params: 52,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.5210 - acc: 0.8546\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.2534 - acc: 0.9269\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.2027 - acc: 0.9414\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.1702 - acc: 0.9515\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.1463 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.1285 - acc: 0.9631\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.1147 - acc: 0.9671\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1037 - acc: 0.9701\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0945 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0866 - acc: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d624fd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "\n",
    "# Train the model\n",
    "    # Number of epochs: 10 (i.e. how many times to loop over the training data)\n",
    "    # Batch size: 16 (how big our \"drunk walk\" samples should be)\n",
    "    # See: 'fit()' in https://keras.io/models/sequential/\n",
    "    \n",
    "model.fit(x_train_flattened, y_train_categorical, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/step\n",
      "\n",
      "Final test cost:  0.10325387454628944\n",
      "Final test accuracy:  0.9694\n"
     ]
    }
   ],
   "source": [
    "# Evaluate trained model on test data\n",
    "\n",
    "# Returns final test loss & test accuracy\n",
    "    # See: 'evaluate' in https://keras.io/models/sequential/\n",
    "loss_and_metrics = model.evaluate(x_test_flattened, y_test_categorical, batch_size=128)\n",
    "final_cost = loss_and_metrics[0]\n",
    "final_accuracy = loss_and_metrics[1]\n",
    "\n",
    "print()\n",
    "print(\"Final test cost: \", final_cost)\n",
    "print(\"Final test accuracy: \", final_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Sanity Check:** Make sure the our neural network's predictions match up with the actual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output vector:  [1.2435037e-06 3.6855128e-09 3.0144693e-07 4.9909951e-05 1.3093435e-04\n",
      " 3.1708862e-04 1.4568918e-09 7.6785445e-04 1.7215608e-04 9.9856049e-01]\n",
      "Predicted digit:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeSIvxAUoQfSOr/AU7a8vPtZHryAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128bc83c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_num = 12 # which test sample to look at. Play around with this number to see how \\\n",
    "    # our neural network performs on different test images\n",
    "\n",
    "# Predicted class\n",
    "test_sample = np.expand_dims(x_test_flattened[sample_num], axis=0) # pick out a one-sample \"batch\" to feed into model\n",
    "predicted_scores = model.predict(test_sample) # outputted probabilities vector\n",
    "print(\"Output vector: \", predicted_scores[0]) # print predicted scores\n",
    "\n",
    "predicted_class = np.argmax(predicted_scores) # pick the class with highest probability --> final prediction\n",
    "print(\"Predicted digit: \", predicted_class) # print predicted classification\n",
    "\n",
    "# Show actual input image\n",
    "plt.imshow(x_test[sample_num], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats! You just did deep learning!\n",
    "If you have extra time, feel free to play around with the hyperparameters (number of neurons per layer, number of epochs, batch size, etc.) to see if you can improve the network's final accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
